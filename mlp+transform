import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from torch.utils.data import TensorDataset, DataLoader

# ========================
# Global Configurations
# ========================
MIN_SAMPLES_PER_SECTOR = 50
REPORT_COLS = ['Sector', 'Samples', 'RMSE', 'MSE', 'MAE', 'R²', 'MAPE(%)']
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ========================
# Main Workflow
# ========================
def main():
    # Load and preprocess data
    df = load_and_preprocess()

    # Get valid sectors
    sector_metrics = []
    valid_sectors = get_valid_sectors(df)

    for sector in valid_sectors:
        sector_df = df[df['sector'] == sector].copy()
        sector_df = sector_df.drop(columns=['sector'])

        if len(sector_df) < MIN_SAMPLES_PER_SECTOR:
            print(f"Skipping {sector}: Insufficient samples ({len(sector_df)})")
            continue

        print(f"\n{'=' * 40}\nProcessing Sector: {sector} ({len(sector_df)} samples)\n{'=' * 40}")

        # Feature engineering
        X, y, preprocessor, feature_names = feature_engineering(sector_df)

        # Split dataset
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Create DataLoader
        batch_size = 32
        train_dataset = TensorDataset(X_train, y_train)
        test_dataset = TensorDataset(X_test, y_test)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(test_dataset, batch_size=batch_size)

        # Model training
        model = MLP(input_dim=X.shape[1])
        trained_model = train_model(model, train_loader, val_loader)

        # Evaluation
        metrics = evaluate_model(trained_model, X_test, y_test, sector, len(sector_df))
        sector_metrics.append(metrics)

        # Save pipeline
        save_pipeline(trained_model, preprocessor, feature_names, sector)

    # Generate report
    generate_sector_report(pd.DataFrame(sector_metrics, columns=REPORT_COLS))


# ========================
# Data Preprocessing
# ========================
def load_and_preprocess():
    """Data loading and cleaning pipeline"""
    df = pd.read_excel('1.xlsx')
    df = df.rename(columns={
        'horizon (days)': 'holding_period',
        'expected_return (yearly)': 'expected_return'
    })
    df = df.drop(columns=['company', 'date_BUY_fix', 'date_SELL_fix'], errors='ignore')

    # Label encoding
    df['investment'] = LabelEncoder().fit_transform(df['investment'])

    # Calculate returns
    valid_prices = (df['price_BUY'] > 1e-6) & (df['price_SELL'] > 1e-6)
    df = df[valid_prices].copy()
    df['log_return'] = np.log(df['price_SELL'] / df['price_BUY'])
    df['annualized_return'] = df['log_return'] * (365 / df['holding_period'].clip(lower=1))
    df['real_return'] = df['annualized_return'] - df['inflation']

    # Filter outliers
    lower, upper = df['real_return'].quantile([0.01, 0.99])
    return df[(df['real_return'] > lower) & (df['real_return'] < upper)]


def get_valid_sectors(df):
    """Get sectors with sufficient samples"""
    sector_counts = df['sector'].value_counts()
    return sector_counts[sector_counts >= MIN_SAMPLES_PER_SECTOR].index.tolist()


# ========================
# Feature Engineering
# ========================
def feature_engineering(df):
    """Feature processing pipeline"""
    numeric_features = [
        'PE_ratio', 'Volatility_Buy', 'ROE_ratio',
        'NetProfitMargin_ratio', 'current_ratio', 'PS_ratio',
        'investment', 'holding_period'
    ]

    preprocessor = ColumnTransformer([
        ('scaler', StandardScaler(), numeric_features)
    ])

    X = preprocessor.fit_transform(df).astype(np.float32)
    y = df['real_return'].values.astype(np.float32)

    return (torch.tensor(X, dtype=torch.float32),
            torch.tensor(y, dtype=torch.float32).unsqueeze(1),
            preprocessor,
            numeric_features)


# ========================
# MLP Model
# ========================
class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim=128):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, x):
        return self.model(x)


# ========================
# Model Training
# ========================
def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, patience=10):
    """Model training with early stopping"""
    model.to(device)
    criterion = nn.MSELoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr)

    best_loss = float('inf')
    early_stop_counter = 0

    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            loss = criterion(model(X_batch), y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # Validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for X_val, y_val in val_loader:
                X_val, y_val = X_val.to(device), y_val.to(device)
                val_loss += criterion(model(X_val), y_val).item()

        # Early stopping
        avg_val_loss = val_loss / len(val_loader)
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            torch.save(model.state_dict(), 'best_model.pth')
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            if early_stop_counter >= patience:
                print(f"Early stopping at epoch {epoch + 1}")
                break

    model.load_state_dict(torch.load('best_model.pth'))
    return model


# ========================
# Model Evaluation
# ========================
def evaluate_model(model, X_test, y_test, sector, n_samples):
    """Evaluate model performance"""
    model.eval()
    with torch.no_grad():
        y_pred = model(X_test.to(device)).cpu().numpy()

    y_true = y_test.cpu().numpy()

    # Calculate metrics
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = 100 * np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-9)))

    # Print results
    print(f"\nEvaluation Results for {sector}:")
    print(f"RMSE: {rmse:.4f}  MSE: {mse:.4f}")
    print(f"MAE: {mae:.4f}  R²: {r2:.4f}")
    print(f"MAPE: {mape:.2f}%")

    return [sector, n_samples, rmse, mse, mae, r2, mape]


# ========================
# Pipeline Saving
# ========================
def save_pipeline(model, preprocessor, feature_names, sector):
    """Save model components"""
    safe_name = sector.replace("/", "_").replace(":", "-")
    save_dir = Path(f"model_pipelines/{safe_name}")
    save_dir.mkdir(parents=True, exist_ok=True)

    torch.save(model.state_dict(), save_dir / 'model.pt')
    joblib.dump(preprocessor, save_dir / 'preprocessor.pkl')
    pd.Series(feature_names).to_csv(save_dir / 'features.csv', index=False)
    print(f"Pipeline saved to {save_dir}")


# ========================
# Report Generation
# ========================
def generate_sector_report(metrics_df):
    """Generate performance report"""
    # Save Excel
    metrics_df.sort_values('RMSE').to_excel("Sector_Performance_Report.xlsx", index=False)

    # Visualization
    plt.figure(figsize=(12, 8))
    metrics_df.set_index('Sector').plot(
        kind='barh',
        subplots=True,
        layout=(3, 2),
        figsize=(15, 12),
        sharex=False
    )
    plt.suptitle("Cross-sector Performance Comparison")
    plt.tight_layout()
    plt.savefig('Sector_Comparison.png')
    plt.show()


if __name__ == "__main__":
    main()
