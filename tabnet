import pandas as pd
import numpy as np
import torch
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from pytorch_tabnet.tab_model import TabNetRegressor

# ========================
# Global Configuration
# ========================
MIN_SAMPLES_PER_SECTOR = 50  # Industry minimum sample threshold
REPORT_COLS = ['industry', 'sample', 'RMSE', 'MSE', 'MAE', 'R²', 'MAPE(%)', 'median APE(%)']  # Added median APE


# ========================
# Main process
# ========================
def main():
    df = load_and_preprocess()
    valid_sectors = get_valid_sectors(df)
    sector_metrics = []

    for sector in valid_sectors:
        sector_df = df[df['sector'] == sector].copy()

        if len(sector_df) < MIN_SAMPLES_PER_SECTOR:
            print(f"skip {sector}: Insufficient-sample ({len(sector_df)})")
            continue

        print(f"\n{'=' * 40}\nprocessing industry: {sector} ({len(sector_df)} sample)\n{'=' * 40}")

        # Industry-specific feature engineering
        X, y, preprocessor = sector_feature_engineering(sector_df)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Model training (no early stop)
        model = train_tabnet(X_train, y_train, X_test, y_test)

        # Evaluation and preservation
        metrics = evaluate_sector(model, X_test, y_test, sector, len(sector_df))
        sector_metrics.append(metrics)
        save_sector_pipeline(model, preprocessor, sector)

    # Generate industry reports
    generate_sector_report(pd.DataFrame(sector_metrics, columns=REPORT_COLS))


# ========================
# Data preprocessing (keeping the original logic)
# ========================
def load_and_preprocess():
    try:
        df = pd.read_excel('1.xlsx')
        print(f"Data loaded successfully. Sample: {len(df):,}")
    except Exception as e:
        raise ValueError(f"File loading failure: {e}")

    # Standardization of listing
    df = df.rename(columns={
        'horizon (days)': 'holding_period',
        'expected_return (yearly)': 'expected_return'
    })

    # Removes the feature column
    df = df.drop(columns=['company', 'date_BUY_fix', 'date_SELL_fix'], errors='ignore')

    # Label encoding
    df['investment'] = LabelEncoder().fit_transform(df['investment'])

    # calculate returns
    df = calculate_returns(df)

    # Outlier processing
    df = filter_extreme_values(df)

    return df


def calculate_returns(df):
    valid_prices = (df['price_BUY'] > 1e-6) & (df['price_SELL'] > 1e-6)
    df = df[valid_prices].copy()

    df['log_return'] = np.log(df['price_SELL'] / df['price_BUY'])
    df['annualized_return'] = df['log_return'] * (365 / df['holding_period'].clip(lower=1))
    df['real_return'] = df['annualized_return'] - df['inflation']
    return df


def filter_extreme_values(df):
    lower, upper = df['real_return'].quantile([0.01, 0.99])
    print(f"Income filtering range: [{lower:.4f}, {upper:.4f}]")
    return df[(df['real_return'] > lower) & (df['real_return'] < upper)]


# ========================
# Industry processing module
# ========================
def get_valid_sectors(df):
    """ Access to effective industries"""
    sector_counts = df['sector'].value_counts()
    return sector_counts[sector_counts >= MIN_SAMPLES_PER_SECTOR].index.tolist()


def sector_feature_engineering(df):
    """ Industry characteristic engineering"""
    numeric_features = [
        'PE_ratio', 'Volatility_Buy', 'ROE_ratio',
        'NetProfitMargin_ratio', 'current_ratio', 'PS_ratio',
        'investment', 'holding_period'
    ]

    preprocessor = ColumnTransformer([
        ('scaler', StandardScaler(), numeric_features)
    ])

    X = preprocessor.fit_transform(df).astype(np.float32)
    y = df['real_return'].values.astype(np.float32)

    return X, y, preprocessor


def train_tabnet(X_train, y_train, X_val, y_val):
    """ Disable early stop model training"""
    tabnet = TabNetRegressor(
        n_d=32,
        n_a=32,
        n_steps=5,
        gamma=1.2,
        seed=42,
        optimizer_fn=torch.optim.Adam,
        optimizer_params=dict(lr=1e-2),
        mask_type='sparsemax',
    )

    tabnet.fit(
        X_train=X_train,
        y_train=y_train.reshape(-1, 1),
        eval_set=[(X_val, y_val.reshape(-1, 1))],
        max_epochs=100,  # Increase training rounds
        batch_size=256,
        eval_metric=['rmse']
    )
    return tabnet


# ========================
# Evaluation module (New detailed indicators)
# ========================
def evaluate_sector(model, X_test, y_test, sector, n_samples):
    """ Industry evaluation index"""
    y_pred = model.predict(X_test)

    # Core index calculation
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # APE calculation (new median)
    epsilon = 1e-6
    ape_values = 100 * np.abs((y_test - y_pred) / (np.abs(y_test) + epsilon))
    mape = np.mean(ape_values)
    median_ape = np.median(ape_values)

    # Real-time print results
    print("\n" + "=" * 60)
    print(f"{sector} Evaluate Results (sample: {n_samples})")
    print("-" * 60)
    print(f"{'RMSE':<15}{rmse:>15.4f}")
    print(f"{'MSE':<15}{mse:>15.4f}")
    print(f"{'MAE':<15}{mae:>15.4f}")
    print(f"{'R²':<15}{r2:>15.4f}")
    print(f"{'MAPE (%)':<15}{mape:>15.2f}")
    print(f"{'Median APE (%)':<15}{median_ape:>15.2f}")
    print("=" * 60 + "\n")

    return [sector, n_samples, rmse, mae, mse, r2, mape, median_ape]


# ========================
# Model saving (optimized path processing)
# ========================
def save_sector_pipeline(model, preprocessor, sector):
    """ Safe save model"""
    safe_name = sector.replace("/", "_").replace(":", "-")  # Handle special characters
    save_dir = Path(f"sector_models/{safe_name}")
    save_dir.mkdir(parents=True, exist_ok=True)

    # Save the model and preprocess
    model.save_model(save_dir / f"{safe_name}_tabnet.zip")
    joblib.dump(preprocessor, save_dir / "preprocessor.pkl")
    print(f" The model was saved to: {save_dir}/")


# ========================
# Report generation (Enhanced visualization)
# ========================
def generate_sector_report(metrics_df):
    """ Generate multidimensional reports"""
    # Excel report
    metrics_df.sort_values('RMSE').to_excel("Industry performance report.xlsx", index=False)

    # Console Output
    print("\n" + "=" * 80)
    print(" Industry performance summary".center(78))
    print("=" * 80)
    print(f"{'industry':<20}{'sample':>6}{'RMSE':>8}{'MSE':>10}{'MAE':>8}{'R²':>6}{'MAPE(%)':>8}{'median APE(%)':>10}")
    print("-" * 80)

    for _, row in metrics_df.sort_values('RMSE').iterrows():
        print(f"{row['industry'][:18]:<20}"
              f"{row['sample']:>6}"
              f"{row['RMSE']:>8.4f}"
              f"{row['MSE']:>10.4f}"
              f"{row['MAE']:>8.4f}"
              f"{row['R²']:>6.3f}"
              f"{row['MAPE(%)']:>8.2f}"
              f"{row['median APE(%)']:>10.2f}")

    print("=" * 80)

    # Visual display
    plt.figure(figsize=(18, 6))
    metrics_df.set_index('industry').plot(
        y=['RMSE', 'MAE', 'MAPE(%)'],
        kind='barh',
        subplots=True,
        layout=(1, 3),
        sharex=False,
        legend=False
    )
    plt.suptitle("Cross-industry performance comparison")
    plt.tight_layout()
    plt.savefig('Comparison of industry indicators.png')
    plt.show()


# ========================
# Enter Execs
# ========================
if __name__ == "__main__":
    main()
